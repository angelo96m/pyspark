{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PySparkTmp\") \\\n",
    "    .getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://vmi455856.contaboserver.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.7</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkTmp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc89655ee10>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark #local[*] con * significa che utilizza tutti i core della macchina locale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella = spark.read.csv(\"./convertcsv.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella.printSchema() #mostra com'è formattato l'Header della tabella del file csv importato. Nota: time e items_sold qui sono delle stringhe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(_c0,StringType,true),StructField(_c1,StringType,true),StructField(_c2,StringType,true)))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabella.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|       _c0|       _c1|       _c2|\n",
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "|2116/12/04|        NU|       875|\n",
      "|2120/02/28|        SK|       231|\n",
      "|2072/05/30|        NL|       855|\n",
      "|2056/03/29|        NT|       758|\n",
      "|2112/12/19|        NT|       101|\n",
      "|2075/11/07|        NL|       682|\n",
      "|2097/01/26|        NB|       923|\n",
      "|2053/12/25|        NU|       935|\n",
      "|2087/05/01|        NL|       535|\n",
      "|2115/11/03|        QC|       768|\n",
      "|2051/11/20|        NL|       357|\n",
      "|2052/01/01|        BC|       422|\n",
      "|2040/04/18|        NL|       669|\n",
      "|2042/07/23|        NS|       523|\n",
      "|2045/08/30|        BC|       163|\n",
      "|2085/08/16|        NT|       526|\n",
      "|2058/10/26|        SK|       282|\n",
      "|2078/02/07|        NT|       475|\n",
      "|2030/01/21|        NT|       677|\n",
      "+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella = spark.read.csv(\"./convertcsv.csv\", header=True) #per visualizzare in modo corretto l'header della tasbella. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2116/12/04|        NU|       875|\n",
      "|2120/02/28|        SK|       231|\n",
      "|2072/05/30|        NL|       855|\n",
      "|2056/03/29|        NT|       758|\n",
      "|2112/12/19|        NT|       101|\n",
      "|2075/11/07|        NL|       682|\n",
      "|2097/01/26|        NB|       923|\n",
      "|2053/12/25|        NU|       935|\n",
      "|2087/05/01|        NL|       535|\n",
      "|2115/11/03|        QC|       768|\n",
      "|2051/11/20|        NL|       357|\n",
      "|2052/01/01|        BC|       422|\n",
      "|2040/04/18|        NL|       669|\n",
      "|2042/07/23|        NS|       523|\n",
      "|2045/08/30|        BC|       163|\n",
      "|2085/08/16|        NT|       526|\n",
      "|2058/10/26|        SK|       282|\n",
      "|2078/02/07|        NT|       475|\n",
      "|2030/01/21|        NT|       677|\n",
      "|2035/05/20|        NT|       923|\n",
      "+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- items_sold: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una nuova variabile (tabella2) in cui convertire i valori nel tipo giusto del file csv. Ovvero il campo time lo converto nel tipo date\n",
    "#il campo items_sold, prima era stringa, ora lo converto in interi. \n",
    "#to_date: si specifica il campo da convertire e il formato in cui si vuole specificare la data \n",
    "#Per convertire da String a Integer bisogna fare il cast. \n",
    "import pyspark.sql.functions as f\n",
    "tabella2 = tabella.withColumn(\"time\", f.to_date(\"time\", \"yyyy/MM/dd\")) \\\n",
    "    .withColumn(\"items_sold\", f.col(\"items_sold\").cast(\"integer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: date (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- items_sold: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.printSchema() #è possibile notare che i tipi per le colonne sono corretti. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2116-12-04|        NU|       875|\n",
      "|2120-02-28|        SK|       231|\n",
      "|2072-05-30|        NL|       855|\n",
      "|2056-03-29|        NT|       758|\n",
      "|2112-12-19|        NT|       101|\n",
      "|2075-11-07|        NL|       682|\n",
      "|2097-01-26|        NB|       923|\n",
      "|2053-12-25|        NU|       935|\n",
      "|2087-05-01|        NL|       535|\n",
      "|2115-11-03|        QC|       768|\n",
      "|2051-11-20|        NL|       357|\n",
      "|2052-01-01|        BC|       422|\n",
      "|2040-04-18|        NL|       669|\n",
      "|2042-07-23|        NS|       523|\n",
      "|2045-08-30|        BC|       163|\n",
      "|2085-08-16|        NT|       526|\n",
      "|2058-10-26|        SK|       282|\n",
      "|2078-02-07|        NT|       475|\n",
      "|2030-01-21|        NT|       677|\n",
      "|2035-05-20|        NT|       923|\n",
      "+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2106-08-10|        AB|       984|\n",
      "|2088-03-06|        AB|       440|\n",
      "|2053-11-02|        AB|       760|\n",
      "|2022-08-24|        AB|       901|\n",
      "|2119-01-27|        AB|       165|\n",
      "|2053-12-02|        AB|       935|\n",
      "|2049-08-22|        AB|       700|\n",
      "+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.where(f.col(\"department\")==\"AB\").show() #mostra solo i dipartimenti con nome: \"AB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2106-08-10|        AB|       984|\n",
      "|2088-03-06|        AB|       440|\n",
      "|2053-11-02|        AB|       760|\n",
      "|2022-08-24|        AB|       901|\n",
      "|2119-01-27|        AB|       165|\n",
      "|2053-12-02|        AB|       935|\n",
      "|2049-08-22|        AB|       700|\n",
      "+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.where(\"department='AB'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2106-08-10|        AB|       984|\n",
      "|2053-11-02|        AB|       760|\n",
      "|2022-08-24|        AB|       901|\n",
      "|2053-12-02|        AB|       935|\n",
      "|2049-08-22|        AB|       700|\n",
      "+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.where((f.col(\"department\")==\"AB\") & (f.col(\"items_sold\")>=500)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|department|\n",
      "+----------+\n",
      "|        NS|\n",
      "|        NL|\n",
      "|        NT|\n",
      "|        QC|\n",
      "|        BC|\n",
      "|        MB|\n",
      "|        NU|\n",
      "|        SK|\n",
      "|        ON|\n",
      "|        AB|\n",
      "|        PE|\n",
      "|        YT|\n",
      "|        NB|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.where((f.col(\"items_sold\")>=700)).select(\"department\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabella2.createOrReplaceTempView(\"sales\") #permette di rinominare il nome del file .csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|department|\n",
      "+----------+\n",
      "|        NS|\n",
      "|        NL|\n",
      "|        NT|\n",
      "|        QC|\n",
      "|        BC|\n",
      "|        MB|\n",
      "|        NU|\n",
      "|        SK|\n",
      "|        ON|\n",
      "|        AB|\n",
      "|        PE|\n",
      "|        YT|\n",
      "|        NB|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT(department)\n",
    "FROM sales\n",
    "WHERE items_sold >= 700\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|department|sum(items_sold)|\n",
      "+----------+---------------+\n",
      "|        NL|           6750|\n",
      "|        NB|           5502|\n",
      "|        NT|           4909|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query: raggruppare per dipartimenti. I primi 3 Dipartimenti che hanno venduto di più in ordine descrente. \n",
    "query = \"\"\"\n",
    "SELECT department, SUM(items_sold)\n",
    "FROM sales\n",
    "GROUP BY department\n",
    "ORDER BY Sum(items_sold) DESC\n",
    "LIMIT(3)\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark.sql.sampleData'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-d645e35c3769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampleData\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark.sql.sampleData'"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.sampleData as sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|department|sum(items_sold)|\n",
      "+----------+---------------+\n",
      "|        NL|           6750|\n",
      "|        NB|           5502|\n",
      "|        NT|           4909|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT department, SUM(items_sold)\n",
    "FROM sales\n",
    "GROUP BY department\n",
    "ORDER BY Sum(items_sold) DESC\n",
    "LIMIT(3)\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|department|\n",
      "+----------+\n",
      "|        NS|\n",
      "|        NL|\n",
      "|        NT|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT department\n",
    "FROM sales\n",
    "GROUP BY department\n",
    "LIMIT(3)\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2116-12-04|        NU|       875|\n",
      "|2120-02-28|        SK|       231|\n",
      "|2072-05-30|        NL|       855|\n",
      "|2056-03-29|        NT|       758|\n",
      "|2112-12-19|        NT|       101|\n",
      "|2075-11-07|        NL|       682|\n",
      "|2097-01-26|        NB|       923|\n",
      "|2053-12-25|        NU|       935|\n",
      "|2087-05-01|        NL|       535|\n",
      "|2115-11-03|        QC|       768|\n",
      "|2051-11-20|        NL|       357|\n",
      "|2052-01-01|        BC|       422|\n",
      "|2040-04-18|        NL|       669|\n",
      "|2042-07-23|        NS|       523|\n",
      "|2045-08-30|        BC|       163|\n",
      "|2085-08-16|        NT|       526|\n",
      "|2058-10-26|        SK|       282|\n",
      "|2078-02-07|        NT|       475|\n",
      "|2030-01-21|        NT|       677|\n",
      "|2035-05-20|        NT|       923|\n",
      "+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fc89655ee10>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+--------------+-----+\n",
      "|        column0|       column1|       column2|label|\n",
      "+---------------+--------------+--------------+-----+\n",
      "|05:49:56.604899|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604900|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604899|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604900|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604899|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604900|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604899|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604900|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604899|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604900|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604899|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604900|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604899|10.0.0.2.54880| 10.0.0.3.5001|    2|\n",
      "|05:49:56.604908| 10.0.0.3.5001|10.0.0.2.54880|    2|\n",
      "|05:49:56.604908| 10.0.0.3.5001|10.0.0.2.54880|    2|\n",
      "|05:49:56.604908| 10.0.0.3.5001|10.0.0.2.54880|    2|\n",
      "|05:49:56.604908| 10.0.0.3.5001|10.0.0.2.54880|    2|\n",
      "|05:49:56.604908| 10.0.0.3.5001|10.0.0.2.54880|    2|\n",
      "|05:49:56.604908| 10.0.0.3.5001|10.0.0.2.54880|    2|\n",
      "|05:49:56.604908| 10.0.0.3.5001|10.0.0.2.54880|    2|\n",
      "+---------------+--------------+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creare una semplice tabella \n",
    "tab =  spark.createDataFrame([(\"05:49:56.604899\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604900\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604899\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604900\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604899\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604900\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604899\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604900\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604899\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604900\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604899\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604900\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604899\", \"10.0.0.2.54880\", \"10.0.0.3.5001\",  2),\n",
    "  (\"05:49:56.604908\", \"10.0.0.3.5001\",  \"10.0.0.2.54880\", 2),\n",
    "  (\"05:49:56.604908\", \"10.0.0.3.5001\",  \"10.0.0.2.54880\", 2),\n",
    "  (\"05:49:56.604908\", \"10.0.0.3.5001\",  \"10.0.0.2.54880\", 2),\n",
    "  (\"05:49:56.604908\", \"10.0.0.3.5001\",  \"10.0.0.2.54880\", 2),\n",
    "  (\"05:49:56.604908\", \"10.0.0.3.5001\",  \"10.0.0.2.54880\", 2),\n",
    "  (\"05:49:56.604908\", \"10.0.0.3.5001\",  \"10.0.0.2.54880\", 2),\n",
    "  (\"05:49:56.604908\", \"10.0.0.3.5001\",  \"10.0.0.2.54880\", 2)],\n",
    "                           [\"column0\", \"column1\", \"column2\", \"label\"])\n",
    "tab.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- column0: string (nullable = true)\n",
      " |-- column1: string (nullable = true)\n",
      " |-- column2: string (nullable = true)\n",
      " |-- label: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tab.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|total|\n",
      "+----------+-----+\n",
      "|        NL| 6750|\n",
      "|        NB| 5502|\n",
      "|        NT| 4909|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query: raggruppare per dipartimenti. I primi 3 Dipartimenti che hanno venduto di più in ordine descrente. \n",
    "#.agg() spercifica una funzione di aggregazione, tipo: sum, avg ecc \n",
    "tabella2.groupBy(\"department\").agg(f.sum(\"items_sold\").alias(\"total\")).orderBy(f.desc(\"total\")).limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|massimo|\n",
      "+-------+\n",
      "|    993|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query: items_sold massimo e minimo \n",
    "tabella2.agg(f.max(\"items_sold\").alias(\"massimo\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Massimo|\n",
      "+-------+\n",
      "|    993|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT MAX(items_sold) AS Massimo\n",
    "FROM sales \n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|minimo|\n",
      "+------+\n",
      "|    47|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query dove mostro il minimo di items_sold \n",
    "tabella2.agg(f.min(\"items_sold\").alias(\"minimo\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|min(items_sold)|\n",
      "+---------------+\n",
      "|             47|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT MIN(items_sold)\n",
    "from sales\n",
    "\"\"\"\n",
    "spark.sql(query).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|DISTINCT|\n",
      "+--------+\n",
      "|     833|\n",
      "|     513|\n",
      "|     211|\n",
      "|     101|\n",
      "|     939|\n",
      "|     436|\n",
      "|     784|\n",
      "|     984|\n",
      "|     875|\n",
      "|     604|\n",
      "|     727|\n",
      "|     758|\n",
      "|     855|\n",
      "|      47|\n",
      "|     185|\n",
      "|     935|\n",
      "|     768|\n",
      "|     274|\n",
      "|     689|\n",
      "|     442|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#query: raggruppare gli items_sold uguali \n",
    "query= \"\"\"\n",
    "SELECT items_sold DISTINCT \n",
    "from sales\n",
    "GROUP BY items_sold \n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2116-12-04|        NU|       875|\n",
      "|2120-02-28|        SK|       231|\n",
      "|2072-05-30|        NL|       855|\n",
      "|2056-03-29|        NT|       758|\n",
      "|2112-12-19|        NT|       101|\n",
      "|2075-11-07|        NL|       682|\n",
      "|2097-01-26|        NB|       923|\n",
      "|2053-12-25|        NU|       935|\n",
      "|2087-05-01|        NL|       535|\n",
      "|2115-11-03|        QC|       768|\n",
      "|2051-11-20|        NL|       357|\n",
      "|2052-01-01|        BC|       422|\n",
      "|2040-04-18|        NL|       669|\n",
      "|2042-07-23|        NS|       523|\n",
      "|2045-08-30|        BC|       163|\n",
      "|2085-08-16|        NT|       526|\n",
      "|2058-10-26|        SK|       282|\n",
      "|2078-02-07|        NT|       475|\n",
      "|2030-01-21|        NT|       677|\n",
      "|2035-05-20|        NT|       923|\n",
      "+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|department|sum(items_sold)|\n",
      "+----------+---------------+\n",
      "|        NS|           3593|\n",
      "|        NL|           6750|\n",
      "|        NT|           4909|\n",
      "|        QC|           4664|\n",
      "|        BC|           3830|\n",
      "|        MB|           2776|\n",
      "|        NU|           4584|\n",
      "|        SK|           4486|\n",
      "|        ON|           2595|\n",
      "|        AB|           4885|\n",
      "|        PE|            884|\n",
      "|        YT|           3810|\n",
      "|        NB|           5502|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query: somma degli items_sold in base in base al dipartimento \n",
    "query = \"\"\"\n",
    "SELECT department, sum(items_sold)\n",
    "from sales\n",
    "group by department \n",
    "\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|somma|\n",
      "+----------+-----+\n",
      "|        NS| 3593|\n",
      "|        NL| 6750|\n",
      "|        NT| 4909|\n",
      "|        QC| 4664|\n",
      "|        BC| 3830|\n",
      "|        MB| 2776|\n",
      "|        NU| 4584|\n",
      "|        SK| 4486|\n",
      "|        ON| 2595|\n",
      "|        AB| 4885|\n",
      "|        PE|  884|\n",
      "|        YT| 3810|\n",
      "|        NB| 5502|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query: somma degli items_sold in base in base al dipartimento \n",
    "tabella2.groupBy(\"department\").agg(f.sum(\"items_sold\").alias(\"somma\")).select(\"department\", \"somma\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|department|            media|\n",
      "+----------+-----------------+\n",
      "|        NB|500.1818181818182|\n",
      "|        QC|518.2222222222222|\n",
      "|        NS|598.8333333333334|\n",
      "|        YT|            635.0|\n",
      "|        ON|           648.75|\n",
      "|        NL|            675.0|\n",
      "|        AB|697.8571428571429|\n",
      "|        PE|            884.0|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query: media degli items_sold in base al dipartimento \n",
    "query = \"\"\"\n",
    "SELECT department, avg(items_sold) AS media\n",
    "from sales\n",
    "GROUP BY department\n",
    "having avg(items_sold)>500\n",
    "ORDER BY media ASC\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|department|            media|\n",
      "+----------+-----------------+\n",
      "|        NB|500.1818181818182|\n",
      "|        QC|518.2222222222222|\n",
      "|        NS|598.8333333333334|\n",
      "|        YT|            635.0|\n",
      "|        ON|           648.75|\n",
      "|        NL|            675.0|\n",
      "|        AB|697.8571428571429|\n",
      "|        PE|            884.0|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Query: media degli items_sold in base al dipartimento e ordinati il base crescente \n",
    "tabella2.groupBy(\"department\").agg(f.avg(\"items_sold\").alias(\"media\")).where(f.avg(\"items_sold\")>500).select(\"department\", \"media\").sort(\"media\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabella2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[time: date, department: string, items: int]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabella2.withColumnRenamed(\"items_sold\", \"items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: date (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- items_sold: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2116-12-04|        NU|       875|\n",
      "|2120-02-28|        SK|       231|\n",
      "|2072-05-30|        NL|       855|\n",
      "+----------+----------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n",
      "|      time|department|items|\n",
      "+----------+----------+-----+\n",
      "|2116-12-04|        NU|  875|\n",
      "|2120-02-28|        SK|  231|\n",
      "|2072-05-30|        NL|  855|\n",
      "+----------+----------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.withColumnRenamed(\"items_sold\", \"items\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2116-12-04|        NU|       875|\n",
      "|2120-02-28|        SK|       231|\n",
      "|2072-05-30|        NL|       855|\n",
      "|2056-03-29|        NT|       758|\n",
      "|2112-12-19|        NT|       101|\n",
      "|2075-11-07|        NL|       682|\n",
      "|2097-01-26|        NB|       923|\n",
      "|2053-12-25|        NU|       935|\n",
      "|2087-05-01|        NL|       535|\n",
      "|2115-11-03|        QC|       768|\n",
      "|2051-11-20|        NL|       357|\n",
      "|2052-01-01|        BC|       422|\n",
      "|2040-04-18|        NL|       669|\n",
      "|2042-07-23|        NS|       523|\n",
      "|2045-08-30|        BC|       163|\n",
      "|2085-08-16|        NT|       526|\n",
      "|2058-10-26|        SK|       282|\n",
      "|2078-02-07|        NT|       475|\n",
      "|2030-01-21|        NT|       677|\n",
      "|2035-05-20|        NT|       923|\n",
      "+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2086-02-04|        NB|       993|\n",
      "|2106-08-10|        AB|       984|\n",
      "|2087-05-26|        NL|       983|\n",
      "|2043-04-07|        BC|       956|\n",
      "|2082-09-11|        YT|       939|\n",
      "|2053-12-02|        AB|       935|\n",
      "|2053-12-25|        NU|       935|\n",
      "|2035-05-20|        NT|       923|\n",
      "|2097-01-26|        NB|       923|\n",
      "|2054-01-05|        QC|       907|\n",
      "|2022-08-24|        AB|       901|\n",
      "|2110-02-11|        QC|       900|\n",
      "|2035-02-21|        ON|       899|\n",
      "|2064-12-06|        NS|       889|\n",
      "|2120-07-10|        PE|       884|\n",
      "|2047-01-14|        QC|       881|\n",
      "|2116-12-04|        NU|       875|\n",
      "|2074-06-29|        YT|       872|\n",
      "|2060-11-25|        YT|       868|\n",
      "|2100-01-20|        NU|       865|\n",
      "+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabella2.sort(f.desc(\"items_sold\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|      time|department|items_sold|\n",
      "+----------+----------+----------+\n",
      "|2119-01-27|        AB|       165|\n",
      "|2106-12-10|        BC|        95|\n",
      "|2120-02-09|        MB|       320|\n",
      "|2104-04-14|        NB|       211|\n",
      "|2119-04-05|        NL|       771|\n",
      "|2113-09-07|        NS|       448|\n",
      "|2112-12-19|        NT|       101|\n",
      "|2116-12-04|        NU|       875|\n",
      "|2058-01-06|        ON|       732|\n",
      "|2120-07-10|        PE|       884|\n",
      "|2119-11-18|        QC|       395|\n",
      "|2120-02-28|        SK|       231|\n",
      "|2099-12-07|        YT|       833|\n",
      "+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Si ordina per tempo, si raggruppa per dipartimento. Si crea una nuova colonna (rn) in cui si hanno le tuple in ordine, ad esempio si prende\n",
    "# sola la prima riga per ogni dipartimento in ordine cronologico .(tramite l'uso dei window di Spark)\n",
    "\n",
    "#In questo esercizio si è realizzata la: somma parziale: \n",
    "#Un totale parziale è la somma di una sequenza di numeri che viene aggiornata ogni volta che viene aggiunto \n",
    "#un nuovo numero alla sequenza, sommando il valore del nuovo numero al totale precedente. \n",
    "from pyspark.sql.window import Window\n",
    "windowTest = Window.partitionBy(\"department\").orderBy(f.desc(\"time\")) #Partition in base ai dipartimenti. Ordine descente in base al time. \n",
    "tabella2.withColumn(\"rn\", f.row_number().over(windowTest)).where(\"rn=1\").drop(\"rn\").show() #Crea una nuova colonna (withColumn) e imposta \n",
    "#il windowTest. Fa la clausola where ed elimina la colonna con drop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+---+\n",
      "|      time|department|items_sold| rn|\n",
      "+----------+----------+----------+---+\n",
      "|2022-08-24|        AB|       901|  1|\n",
      "|2049-08-22|        AB|       700|  2|\n",
      "|2053-11-02|        AB|       760|  3|\n",
      "|2053-12-02|        AB|       935|  4|\n",
      "|2088-03-06|        AB|       440|  5|\n",
      "|2106-08-10|        AB|       984|  6|\n",
      "|2119-01-27|        AB|       165|  7|\n",
      "|2028-10-30|        BC|       507|  1|\n",
      "|2031-04-21|        BC|       439|  2|\n",
      "|2034-07-13|        BC|       261|  3|\n",
      "|2040-07-24|        BC|       294|  4|\n",
      "|2043-04-07|        BC|       956|  5|\n",
      "|2044-06-30|        BC|       693|  6|\n",
      "|2045-08-30|        BC|       163|  7|\n",
      "|2052-01-01|        BC|       422|  8|\n",
      "|2106-12-10|        BC|        95|  9|\n",
      "|2033-09-04|        MB|       261|  1|\n",
      "|2054-01-07|        MB|        87|  2|\n",
      "|2079-12-26|        MB|       784|  3|\n",
      "|2103-05-11|        MB|       525|  4|\n",
      "+----------+----------+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowTest = Window.partitionBy(\"department\").orderBy(f.asc(\"time\"))\n",
    "tabella2.withColumn(\"rn\", f.row_number().over(windowTest)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vista:  tutti i valori che non sono massimi e fare la differenza tra i 2 insiemi, il totale - quello calcolato prima (in SQL)\n",
    "#Bisogna ottenere lo stesso risultato della query di sopra ma in SQL. \n",
    "query = \"\"\"\n",
    "SELECT \n",
    "FROM sales\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
